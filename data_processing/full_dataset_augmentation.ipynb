{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328e4091",
   "metadata": {},
   "source": [
    "### Note: Run this after you download the full dataset if you don't already have it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1deb1",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24769896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import ImageFilter\n",
    "from torchvision.transforms.transforms import RandomAffine, Resize\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7f633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"D:\\\\APS360 Data\\\\Subset\\\\\" # Replace with wherever you store your dataset\n",
    "data_path = \"D:\\\\Training Data-20240401T010113Z-001\\\\Training Data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ff4aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'call', 'del', 'space', 'thumbsup']\n"
     ]
    }
   ],
   "source": [
    "ls = sorted(os.listdir(data_path))\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f98bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path):\n",
    "    img = mpimg.imread(path)\n",
    "    plt.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ddca9",
   "metadata": {},
   "source": [
    "# Define Custom Dataset and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1133938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.classes.sort()\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        instances = []\n",
    "        for target_class in sorted(self.class_to_idx.keys()):\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(self.root_dir, target_class)\n",
    "            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = path, class_index\n",
    "                    instances.append(item)\n",
    "        return instances\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_and_pad_image(image, output_size=(256, 256)):\n",
    "        h, w, _ = image.shape\n",
    "        pad_width = abs(h-w) // 2\n",
    "        \n",
    "        if h > w:\n",
    "            image = cv2.copyMakeBorder(image, 0, 0, pad_width, pad_width, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        elif h < w:\n",
    "            image = cv2.copyMakeBorder(image, pad_width, pad_width, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        \n",
    "        image = cv2.resize(image, output_size)\n",
    "\n",
    "        return Image.fromarray(image)\n",
    "\n",
    "    def balance_dataset(self, desired_count=2000):\n",
    "        # Calculate the current count of images for each class\n",
    "        class_counts = {class_idx: 0 for class_idx in range(len(self.classes))}\n",
    "        for _, target in self.samples:\n",
    "            class_counts[target] += 1\n",
    "\n",
    "        # Identify classes with fewer than desired_count images\n",
    "        classes_with_less = [class_idx for class_idx, count in class_counts.items() if count < desired_count]\n",
    "\n",
    "        # Iterate over the classes with fewer images and augment them\n",
    "        for class_idx in classes_with_less:\n",
    "            # Find indices of images belonging to the current class\n",
    "            class_indices = [idx for idx, (_, target) in enumerate(self.samples) if target == class_idx]\n",
    "            # Calculate the number of images to duplicate\n",
    "            num_to_duplicate = desired_count - class_counts[class_idx]\n",
    "            # Randomly select images from the current class and duplicate them\n",
    "            for _ in range(num_to_duplicate):\n",
    "                random_index = random.choice(class_indices)\n",
    "                image_to_duplicate = self.samples[random_index]\n",
    "                self.samples.append(image_to_duplicate)\n",
    "                class_counts[class_idx] += 1\n",
    "\n",
    "        # Shuffle the balanced dataset\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbf2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE FOR YEONG: I added horizontal flipping here since are dataset\n",
    "# is now impartial to flipping\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert NumPy array to PIL Image\n",
    "    transforms.Lambda(lambda x: CustomImageDataset.resize_and_pad_image(np.array(x))),  # Your custom resize and pad\n",
    "    # Data Augmentation\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(degrees=15, scale=(0.85, 1.15)),  # Random rotation and scaling\n",
    "        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Random blurring\n",
    "        transforms.RandomHorizontalFlip(p=0.2),\n",
    "    ], p=0.15),  # Apply the above transformations with 30% probability\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0103a566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d16f8b2b70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding to ensure reproducibility!\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29004c51",
   "metadata": {},
   "source": [
    "# Let's Process Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e1f739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58088"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomImageDataset(root_dir=data_path, transform=transform)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ead8239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.balance_dataset(desired_count=2000)\n",
    "dataloader = DataLoader(dataset, shuffle=False)\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da61a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed the 0th image\n",
      "\n",
      "Passed the 1000th image\n",
      "\n",
      "Passed the 2000th image\n",
      "\n",
      "Passed the 3000th image\n",
      "\n",
      "Passed the 4000th image\n",
      "\n",
      "Passed the 5000th image\n",
      "\n",
      "Passed the 6000th image\n",
      "\n",
      "Passed the 7000th image\n",
      "\n",
      "Passed the 8000th image\n",
      "\n",
      "Passed the 9000th image\n",
      "\n",
      "Passed the 10000th image\n",
      "\n",
      "Passed the 11000th image\n",
      "\n",
      "Passed the 12000th image\n",
      "\n",
      "Passed the 13000th image\n",
      "\n",
      "Passed the 14000th image\n",
      "\n",
      "Passed the 15000th image\n",
      "\n",
      "Passed the 16000th image\n",
      "\n",
      "Passed the 17000th image\n",
      "\n",
      "Passed the 18000th image\n",
      "\n",
      "Passed the 19000th image\n",
      "\n",
      "Passed the 20000th image\n",
      "\n",
      "Passed the 21000th image\n",
      "\n",
      "Passed the 22000th image\n",
      "\n",
      "Passed the 23000th image\n",
      "\n",
      "Passed the 24000th image\n",
      "\n",
      "Passed the 25000th image\n",
      "\n",
      "Passed the 26000th image\n",
      "\n",
      "Passed the 27000th image\n",
      "\n",
      "Passed the 28000th image\n",
      "\n",
      "Passed the 29000th image\n",
      "\n",
      "Passed the 30000th image\n",
      "\n",
      "Passed the 31000th image\n",
      "\n",
      "Passed the 32000th image\n",
      "\n",
      "Passed the 33000th image\n",
      "\n",
      "Passed the 34000th image\n",
      "\n",
      "Passed the 35000th image\n",
      "\n",
      "Passed the 36000th image\n",
      "\n",
      "Passed the 37000th image\n",
      "\n",
      "Passed the 38000th image\n",
      "\n",
      "Passed the 39000th image\n",
      "\n",
      "Passed the 40000th image\n",
      "\n",
      "Passed the 41000th image\n",
      "\n",
      "Passed the 42000th image\n",
      "\n",
      "Passed the 43000th image\n",
      "\n",
      "Passed the 44000th image\n",
      "\n",
      "Passed the 45000th image\n",
      "\n",
      "Passed the 46000th image\n",
      "\n",
      "Passed the 47000th image\n",
      "\n",
      "Passed the 48000th image\n",
      "\n",
      "Passed the 49000th image\n",
      "\n",
      "Passed the 50000th image\n",
      "\n",
      "Passed the 51000th image\n",
      "\n",
      "Passed the 52000th image\n",
      "\n",
      "Passed the 53000th image\n",
      "\n",
      "Passed the 54000th image\n",
      "\n",
      "Passed the 55000th image\n",
      "\n",
      "Passed the 56000th image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for data and labels\n",
    "i = 0\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for data, labels in dataloader:\n",
    "    all_data.append(data)\n",
    "    all_labels.append(labels)\n",
    "    \n",
    "    if(i%1000 == 0):\n",
    "        print(\"Passed the \" + str(i) + \"th image\\n\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92cbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if your images are extractable from the dataset\n",
    "print(len(all_data))\n",
    "image = all_data[2].numpy()\n",
    "\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "std = torch.tensor(std).view(1, 3, 1, 1)\n",
    "\n",
    "image = std * image + mean\n",
    "image = torch.clamp(image, 0, 1)\n",
    "image = torch.squeeze(image)\n",
    "image = image.permute(1, 2, 0)\n",
    "image = image.cpu().numpy()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf1392",
   "metadata": {},
   "source": [
    "# Let's Save It As A Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d3e0cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "all_data_tensor = torch.cat(all_data, dim=0)\n",
    "all_labels_tensor = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49122bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_data_tensor, 'data_tensor.pth')\n",
    "torch.save(all_labels_tensor, 'labels_tensor.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d6dd4",
   "metadata": {},
   "source": [
    "# Load It Back In and Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.7)  # 70% for training\n",
    "val_size = int(total_size * 0.2)    # 20% for validation\n",
    "test_size = total_size - train_size - val_size  # Remaining 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e57f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
